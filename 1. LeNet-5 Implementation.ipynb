{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. module calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend #keras.backend : \n",
    "from tensorflow.keras.models import Sequential #keras.models.Sequential:\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D,Flatten,Dense\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "#SGD:\n",
    "#RMSprop:\n",
    "#Adam:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataset: MNIST\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "#data load\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#data confirm\n",
    "plt.imshow(x_train[-1], cmap = 'Greys') #해 보니 color인데 숫자 이미지 판단에 흑백/컬러는 중요한게 아니니 'Greys'로 바꾼다.\n",
    "x_train.shape #(total x_train number, height, width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#흑백 영상은 각 픽셀이 0~1 사이의 실수로 된 2-D signal로 표현 할 수 있다. \n",
    "#이차원 신호와 흑백 이미지: 0~255 사이의 값을 0~1로 normalize\n",
    "x_train, x_test = x_train / 255, x_test / 255\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding for label classes\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#we need channel in, so add one more space\n",
    "x_train = x_train[..., np.newaxis]\n",
    "x_test = x_test[..., np.newaxis]\n",
    "print(x_train.shape)#(total x_train number, height, width, channel in)\n",
    "print(x_train[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build LeNet-5 model\n",
    "https://bskyvision.com/418"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyModel():\n",
    "    return Sequential([Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='tanh', input_shape=(28,28,1), padding='same'),#Convolutional layers, input:32*32*1, filter_size:5x5, filters:6개, output:28*28*6\n",
    "                        AveragePooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid'), #Sub-sampling layers, receptive field:2x2, averagepooling, output:14*14*6\n",
    "                        Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation= 'tanh', padding='valid'),#Convolution layers, filter_size:5x5, filters:16개, output:10*10*16\n",
    "                        AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding= 'valid'), #Sub-sampling layers, receptive field:2x2, averagepooling, output:5*5*16\n",
    "                        Conv2D(120, kernel_size=(5, 5), strides=(1, 1), activation= 'tanh', padding= 'valid'),\n",
    "                       \n",
    "                        Flatten(), #fully connection, 120\n",
    "                        #Dense(120, activation = 'relu'),#120\n",
    "                        Dense(84, activation = 'tanh'), #120 -> 84\n",
    "                        Dense(10, activation = 'softmax') #84 -> 10\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "model.compile(optimizer = 'SGD', \n",
    "             loss = 'mean_squared_error', \n",
    "             metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "model.fit(x = x_train, y = y_train, epochs = 10, batch_size = 128, validation_data = (x_test, y_test),verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:90% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:90% !important;}</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
